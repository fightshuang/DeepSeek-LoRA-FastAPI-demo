跟着此视频做出的：【DeepSeek+LoRA+FastAPI】开发人员如何微调大模型并暴露接口给后端调用】 https://www.bilibili.com/video/BV1R6P7eVEtd/?share_source=copy_web&vd_source=54937f7fc746a085e167e38a94abf401
流程见上传的PDF文件，一切资料都是参考此视频的作者！
视频下作者给出的链接{
Demo前端Github地址：https://github.com/huangyf2013320506/magic_conch_frontend.git
Demo后端Github地址（含数据集）：https://github.com/huangyf2013320506/magic_conch_backend.git
笔记文档（.md）：https://pan.quark.cn/s/57939e67d3d0
笔记文档（.pdf）：https://pan.quark.cn/s/d5ed78ef4f76
所有资料：https://pan.quark.cn/s/802cd0c232b4
}
这个UP讲的细且文档做的好，适合我这种小白，可以多关注下这个UP主。跟着视频走了一遍流程（在AutoDL租算力、连接SSH到VSCode中的终端、执行了LLaMA-Factory 安装部署、从huggingface下载模型到LLaMA-Factory环境中、准备数据集微调最重要的还是数据集的构建、在LLama-Factory 的可视化微调界⾯进行微调无代码操作简单、微调完毕导出合并后的模型、创建fast-api环境通过 FastAPI 部署模型并暴露 HTTP 接⼝、然后做前后端工作我没做、还有如何开放服务端⼝到公⽹企业部署等UP主也不会哈哈）。
